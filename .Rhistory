yfit = rnorm(length(mydata ),mean=mean(mydata),sd=sd(mydata))
plot(ecdf(yfit), verticals = TRUE, do.points = FALSE, add=TRUE, col="red")
mydata = read.csv("mydata2_21var.csv", header=F)
mydata = mydata[, 1]
mydata
# Variance for skewness and kurtosis (from first lab)
N = length(mydata)
v_skew = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
v_kur = sqrt(4*(N^2-1)*v_skew^2 / ((N-3)*(N+5))) # must be less than one
########## KOLMOGOROV-SMIRNOV TEST
# Null hypothesis is that mydata distribution is NOT SO FAR from (normal/exp/gamma/unif/chi)
# Alternative hypothesis is that mydata distribution is FAR from (normal/exp/gamma/unif/chi)
alpha = 0.05
N = length(mydata) # = 50
acceptance_region = sqrt(-(1/2)*log(alpha/2)) # = 1.358102
adjusted_acceptance_region = acceptance_region / sqrt(N) # = 0.1920646
skew_standard_error = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
kur_standard_error = sqrt(4*(N^2-1)*skew_standard_error^2 / ((N-3)*(N+5))) # must be less than one
ks_val <- function(ksresult) {
return(ksresult$statistic * sqrt(50))
}
ks_val_print <- function(ksresult, distname) {
#val = ks_val(ksresult)
val = ksresult$statistic
aregion = adjusted_acceptance_region
if (val < aregion) {
cat("K.S (test value) for", distname, "is", val, "and is in the acceptance range (", aregion,")\n")
} else {
cat("K.S (test value) for", distname, "is", val, "and is NOT in the acceptance range (", aregion,")\n")
}
if (ksresult$p.value < aregion) {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is in the acceptance range (", aregion,")\n")
} else {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is NOT in the acceptance range (", aregion,")\n")
}
ksresult
}
# Normal distribution
normksresult = ks.test(mydata, "pnorm", mean=mean(mydata), sd=sd(mydata))
ks_val_print(normksresult, "normal dist") # D = test value = 0.068085
# Exponential distribution
expksresult = ks.test(mydata, "pexp", rate=1/mean(mydata))
ks_val_print(expksresult, "exponential dist") # D = test value = 0.52891
# Uniform distribution
uniformksresult = ks.test(mydata, "punif", min=min(mydata), max=max(mydata))
ks_val_print(uniformksresult, "uniform dist") # D = test value = 0.1936
mydata = read.csv("mydata2_21var.csv", header=F)
mydata = mydata[, 1]
mydata
# Variance for skewness and kurtosis (from first lab)
N = length(mydata)
v_skew = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
v_kur = sqrt(4*(N^2-1)*v_skew^2 / ((N-3)*(N+5))) # must be less than one
########## KOLMOGOROV-SMIRNOV TEST
# Null hypothesis is that mydata distribution is NOT SO FAR from (normal/exp/gamma/unif/chi)
# Alternative hypothesis is that mydata distribution is FAR from (normal/exp/gamma/unif/chi)
alpha = 0.05
N = length(mydata) # = 50
acceptance_region = sqrt(-(1/2)*log(alpha/2)) # = 1.358102
adjusted_acceptance_region = acceptance_region / sqrt(N) # = 0.1920646
skew_standard_error = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
kur_standard_error = sqrt(4*(N^2-1)*skew_standard_error^2 / ((N-3)*(N+5))) # must be less than one
ks_val <- function(ksresult) {
return(ksresult$statistic * sqrt(50))
}
ks_val_print <- function(ksresult, distname) {
#val = ks_val(ksresult)
val = ksresult$statistic
aregion = adjusted_acceptance_region
if (val < aregion) {
cat("K.S (test value) for", distname, "is", val, "and is in the acceptance range (", aregion,")\n")
} else {
cat("K.S (test value) for", distname, "is", val, "and is NOT in the acceptance range (", aregion,")\n")
}
if (ksresult$p.value < alpha) {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is in the acceptance range (", alpha,")\n")
} else {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is NOT in the acceptance range (", alpha,")\n")
}
ksresult
}
# Normal distribution
normksresult = ks.test(mydata, "pnorm", mean=mean(mydata), sd=sd(mydata))
ks_val_print(normksresult, "normal dist") # D = test value = 0.068085
# Exponential distribution
expksresult = ks.test(mydata, "pexp", rate=1/mean(mydata))
ks_val_print(expksresult, "exponential dist") # D = test value = 0.52891
# Uniform distribution
uniformksresult = ks.test(mydata, "punif", min=min(mydata), max=max(mydata))
ks_val_print(uniformksresult, "uniform dist") # D = test value = 0.1936
mydata = read.csv("mydata2_21var.csv", header=F)
mydata = mydata[, 1]
mydata
# Variance for skewness and kurtosis (from first lab)
N = length(mydata)
v_skew = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
v_kur = sqrt(4*(N^2-1)*v_skew^2 / ((N-3)*(N+5))) # must be less than one
########## KOLMOGOROV-SMIRNOV TEST
# Null hypothesis is that mydata distribution is NOT SO FAR from (normal/exp/gamma/unif/chi)
# Alternative hypothesis is that mydata distribution is FAR from (normal/exp/gamma/unif/chi)
alpha = 0.05
N = length(mydata) # = 50
acceptance_region = sqrt(-(1/2)*log(alpha/2)) # = 1.358102
adjusted_acceptance_region = acceptance_region / sqrt(N) # = 0.1920646
skew_standard_error = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3))) # must be nearly equal to others
kur_standard_error = sqrt(4*(N^2-1)*skew_standard_error^2 / ((N-3)*(N+5))) # must be less than one
ks_val <- function(ksresult) {
return(ksresult$statistic * sqrt(50))
}
ks_val_print <- function(ksresult, distname) {
#val = ks_val(ksresult)
val = ksresult$statistic
aregion = adjusted_acceptance_region
if (val < aregion) {
cat("K.S (test value) for", distname, "is", val, "and is in the acceptance range (", aregion,")\n")
} else {
cat("K.S (test value) for", distname, "is", val, "and is NOT in the acceptance range (", aregion,")\n")
}
if (ksresult$p.value > alpha) {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is more than alpha (", alpha,")\n")
} else {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is less than alpha (", alpha,")\n")
}
ksresult
}
# Normal distribution
normksresult = ks.test(mydata, "pnorm", mean=mean(mydata), sd=sd(mydata))
ks_val_print(normksresult, "normal dist") # D = test value = 0.068085
# Exponential distribution
expksresult = ks.test(mydata, "pexp", rate=1/mean(mydata))
ks_val_print(expksresult, "exponential dist") # D = test value = 0.52891
# Uniform distribution
uniformksresult = ks.test(mydata, "punif", min=min(mydata), max=max(mydata))
ks_val_print(uniformksresult, "uniform dist") # D = test value = 0.1936
mydata = read.csv("mydata2_21var.csv", header=F)
mydata = mydata[, 1]
x = mydata[1:25]
y = mydata[26:50]
### t-Student's test for homogeneity
ttestresult = t.test(x, y, alternative = "two.sided", var.equal = FALSE)
alpha = 0.05
critical_value_l = qt(alpha/2, ttestresult$parameter) # = -2.010635
critical_value_r = qt(1-alpha/2, ttestresult$parameter) # = 2.010635
### Wilcoxon-Mann-Whitney test for homogeneity
wt = wilcox.test(x, y, alternative = "two.sided", correct = FALSE)
attributes(wt)	# get names of all test parameters
wt$statistic	# get WMW test statistic value = 361.5
N1 = length(x) # = 25
N2 = length(y) # = 25
mwm_mean = (N1*N2)/2 # = 312.5
mwm_sd = sqrt((1/12)*N1*N2*(N1+N2+1)) # = 51.53882
mwm_zvalue = qnorm(1-alpha/2) # = 1.959964
mwm_standardized_zvalue = (wt$statistic - mwm_mean) / mwm_sd # = 0.9507397
mwm_acceptance_region = qnorm(1-alpha/2) # = 1.959964
### Kolmogorov-Smirnov test for homogeneity
kt = ks.test(x, y, alternative = "two.side")
kt$statistic # D = 0.24
kt$p.value # pvalue = 0.4676
ks_tvalue = kt$statistic * sqrt((N1 * N2)/(N1 + N2)) #  = 0.8485281
ks_acceptance_region = sqrt(-log(alpha/2)/2) # = 1.358102
### Boxplot
boxplot(x, y, names=c("x", "y"))
kt
ttestresult
ttestresult$parameter
alpha = 0.05
# Reading data
dat = read.csv("myvariant.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
# Building histogram
hist(dat)
###### ...
# Initials
alpha = 0.05
# Reading data
dat = read.csv("Data_21var.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
alpha = 0.05
# Reading data
dat = read.csv("Data_21var.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
# Building histogram
hist(dat)
ks_tvalue
acceptance_region_kur(20)
acceptance_region_kur(50)
acceptance_region_kur(40)
v_skew(50)
v_kur(50)
v_kur(50)
alpha = 0.05
# Defining some useful variables and functions
v_skew <- function(N) { return(sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3)))) } # must be nearly equal to others
v_kur <- function(N) { return(sqrt(4*(N^2-1)*v_skew(N)^2 / ((N-3)*(N+5)))) } # must be less than one
coefficient_skew <- function(N) { return(sqrt((6*(N-2))/((N+1)*(N+3)))) }
coefficient_kur <- function(N) { return(sqrt(((24*N)*(N-2)*(N-3))/((N+1)^2*(N+3)*(N+5)))) }
adjusted_kur <- function(dat, N) { return(kurtosis(dat) + (6/(N+1))) }
standard_normal_dist_quantile <- function(N) { return(qnorm(1-alpha/2)) }
acceptance_region_skew <- function(N) { return(qnorm(1-alpha/2)*coefficient_skew(N)) }
acceptance_region_kur <- function(N) { return(qnorm(1-alpha/2)*coefficient_kur(N)) }
ks_acceptance_region <- function() { return(sqrt(-(1/2)*log(alpha/2))) }
ks_tvalue <- function(kstestresult, N1, N2) { return(kstestresult$statistic * sqrt((N1 * N2)/(N1 + N2))) }
ks_acceptance_region_2 <- function() { return(sqrt(-log(alpha/2)/2)) }
ks_adjusted_acceptance_region <- function(N) { return(ks_acceptance_region() / sqrt(N)) }
ks_val_print <- function(ksresult, distname, N) {
val = ksresult$statistic
aregion = ks_adjusted_acceptance_region(N)
if (val < aregion) {
cat("K.S (test value) for", distname, "is", val, "and is in the acceptance range (", aregion, ")\n")
} else {
cat("K.S (test value) for", distname, "is", val, "and is NOT in the acceptance range (", aregion, ")\n")
}
if (ksresult$p.value > alpha) {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is more than alpha (", alpha, ")\n")
} else {
cat("Pvalue for", distname, "is", ksresult$p.value, "and is less than alpha (", alpha, ")\n")
}
ksresult
}
student_critical_value_l <- function(ttestresult) { return(qt(alpha/2, ttestresult$parameter)) }
student_critical_value_r <- function(ttestresult) { return(qt(1-alpha/2, ttestresult$parameter)) }
mwm_mean <- function(N1, N2) { return((N1*N2)/2) }
mwm_sd <- function(N1, N2) { return(sqrt((1/12)*N1*N2*(N1+N2+1))) }
mwm_zvalue <- function() { return(qnorm(1-alpha/2)) }
mwm_standardized_zvalue <- function(wilcoxtestresult, N1, N2) { return((wilcoxtestresult$statistic - mwm_mean(N1, N2)) / mwm_sd(N1, N2)) }
mwm_acceptance_region <- function() { return(qnorm(1-alpha/2)) }
v_kur(50)
v_kur(50)
v_skew(50)
alpha = 0.05
# Reading data
dat = read.csv("Data_21var.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
v_skew(50)
standard_normal_dist_quantile(50)
standard_normal_dist_quantile(N)
ks_acceptance_region()
ks_acceptance_region_2()
ks_adjusted_acceptance_region(50)
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
skew_standard(50)
standard_normal_dist_quantile(50)
skewness(10)
skewness(dat)
# Find outliers
get_without_outliers <- function(data, resids) {
return(subset(data, resids > mean(resids)-2*sd(resids) & resids < mean(resids)+2*sd(resids)))
}
get_last_outlier_index <- function(data, resids) {
last_outlier_index = which.max(abs(resids))
print(paste("Index of max resid =", last_outlier_index, "(removing)"))
return(last_outlier_index)
}
plot_new_resids <- function(newreg, i) {
res_without_outliers = resid(newreg)
plot(res_without_outliers, main=paste("Table", i),
ylim=c(mean(res_without_outliers)-3*sd(res_without_outliers),
mean(res_without_outliers)+3*sd(res_without_outliers)))
abline(h=mean(res_without_outliers), col="red", lwd=2)
abline(h=mean(res_without_outliers)-sd(res_without_outliers), col="darkgreen")
abline(h=mean(res_without_outliers)+sd(res_without_outliers), col="darkgreen")
abline(h=mean(res_without_outliers)-2*sd(res_without_outliers), col="green")
abline(h=mean(res_without_outliers)+2*sd(res_without_outliers), col="green")
abline(h=mean(res_without_outliers)-3*sd(res_without_outliers), col="blue")
abline(h=mean(res_without_outliers)+3*sd(res_without_outliers), col="blue")
return(res_without_outliers)
}
reggress_model <- function(prev_dat, prev_y, prev_res, index, exclude_outliers=TRUE) {
print(paste("Index", index))
new_dat = get_without_outliers(prev_dat, prev_res)
new_y = get_without_outliers(prev_y, prev_res)
if (exclude_outliers == FALSE) {
new_dat = prev_dat
new_y = prev_y
} else {
if (length(prev_y) - length(new_y) != 0) {
print(paste("Outliers found! (", length(prev_y) - length(new_y), ")"))
last_outlier_index = get_last_outlier_index(prev_dat, prev_res)
new_dat = prev_dat[-c(last_outlier_index),]
new_y = prev_y[-c(last_outlier_index)]
} else {
print("No outliers found.")
}
}
#print(paste("Removed", length(prev_y) - length(new_y), "observations."))
new_reg = lm(new_y ~ ., data=new_dat)
print(summary(new_reg))
anova_result = anova(new_reg)
print(anova_result)
print(paste("Residuals sum sq =", tail(anova_result$`Sum Sq`, 1)))
print(paste("Residuals df =", tail(anova_result$Df, 1)))
print(paste("SEE =", sqrt(tail(anova_result$`Sum Sq`,1)/tail(anova_result$Df, 1))))
new_res = plot_new_resids(new_reg, index)
return(list("new_dat" = new_dat, "new_y" = new_y, "new_res" = new_res, "anova_res" = anova_result))
}
# Initials
alpha = 0.05
# Reading data
dat = read.csv("Data_21var.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
plot(dat)
# Initials
alpha = 0.05
# Reading data
dat = read.csv("Data_LW_5.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
plot(dat)
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv")
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the histogram")
hist(dat)
x
dat
###### ...
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv")
# Adjust data if necessary
dat = dat[, 1]
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
# Adjust data if necessary
dat = dat[, 1]
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv")
# Adjust data if necessary
dat = dat[, 1]
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
dat
read.csv("mydata2_21var.csv")
# Reading data
dat = read.csv("mydata2_21var.csv", sep=";")
dat
###### ...
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv", sep=";")
# Adjust data if necessary
dat = dat[, 1]
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
# add more lines on the histogram (for example, to show the normal distribution red line)
#xfit = seq(min(mydata), max(mydata), length=100)
#yfit = dnorm(xfit, mean=mean(mydata), sd=sd(mydata))
#yfit = yfit * diff(h$mids[1:2]) * length(yfit)
#h = hist(mydata, ylim=c(0, max(yfit)))
#lines(xfit, yfit, col="red", lwd=2)
# Summarizing
summary(dat)
kurtosis(dat)
skewness(dat)
coefficient_kur(50)
coefficient_skew()
coefficient_skew(50)
v_skew(50)
v_kur(50)
qnorm(0.95)
pnorm(0.95)
dnorm(0.95)
qnorm(0.05)
standard_normal_dist_quantile(50)
acceptance_region_kur()
acceptance_region_kur(50)
acceptance_region_skew(50)
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv", sep=";")
# Adjust data if necessary
dat = dat[, 1]
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
# add more lines on the histogram (for example, to show the normal distribution red line)
#xfit = seq(min(mydata), max(mydata), length=100)
#yfit = dnorm(xfit, mean=mean(mydata), sd=sd(mydata))
#yfit = yfit * diff(h$mids[1:2]) * length(yfit)
#h = hist(mydata, ylim=c(0, max(yfit)))
#lines(xfit, yfit, col="red", lwd=2)
# Summarizing
summary(dat)
sd(dat)
var(dat)
# Run my variant test function
ks_test_for_normal(dat, N)
ks_test_for_gamma(dat, N)
ks_test_for_gamma(dat, N)
ks_test_for_exponential(dat, N)
ks_test_for_chisquare(dat, N)
dat
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv", sep=";", header=F)
# Adjust data if necessary
dat = dat[, 1]
dat
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
# add more lines on the histogram (for example, to show the normal distribution red line)
#xfit = seq(min(mydata), max(mydata), length=100)
#yfit = dnorm(xfit, mean=mean(mydata), sd=sd(mydata))
#yfit = yfit * diff(h$mids[1:2]) * length(yfit)
#h = hist(mydata, ylim=c(0, max(yfit)))
#lines(xfit, yfit, col="red", lwd=2)
# Summarizing
summary(dat)
sd(dat)
var(dat)
# Run my variant test function
ks_test_for_normal(dat, N)
ks_test_for_gamma(dat, N)
ks_test_for_exponential(dat, N)
ks_test_for_chisquare(dat, N)
# Confidence interval
###### ...
# Initials
alpha = 0.05
# Reading data
dat = read.csv("mydata2_21var.csv", sep=";", header=F)
# Adjust data if necessary
dat = dat[, 1]
dat
N = length(dat)
# Useful functions
source("F:/dev/R/Labworks/exam_helpers_script.R")
# Plotting
plot(dat, xlab="x", ylab="y", main="Title of the plot")
# Building histogram
hist(dat)
# add more lines on the histogram (for example, to show the normal distribution red line)
#xfit = seq(min(mydata), max(mydata), length=100)
#yfit = dnorm(xfit, mean=mean(mydata), sd=sd(mydata))
#yfit = yfit * diff(h$mids[1:2]) * length(yfit)
#h = hist(mydata, ylim=c(0, max(yfit)))
#lines(xfit, yfit, col="red", lwd=2)
# Summarizing
summary(dat)
sd(dat)
var(dat)
# Run my variant test function
ks_test_for_normal(dat, N)
ks_test_for_gamma(dat, N)
ks_test_for_exponential(dat, N)
ks_test_for_chisquare(dat, N)
# Confidence interval
acceptance_region = ks_acceptance_region()
###### ...
